alloy:
  configMap:
    # https://grafana.com/docs/alloy/latest/collect/logs-in-kubernetes/
    content: |
      // local.file_match discovers files on the local filesystem using glob patterns and the doublestar library. It returns an array of file paths.
      local.file_match "node_logs" {
        path_targets = [{
            // Monitor syslog to scrape node-logs
            __path__  = "/var/log/syslog",
            job       = "node/syslog",
            node      = sys.env("HOSTNAME"),
            cluster   = "moto-a1",
        }]
      }

      // loki.source.file reads log entries from files and forwards them to other loki.* components.
      // You can specify multiple loki.source.file components by giving them different labels.
      loki.source.file "node_logs" {
        targets    = local.file_match.node_logs.targets
        forward_to = [loki.write.vl.receiver, otelcol.receiver.loki.gcp_logs.receiver]
      }

      // discovery.kubernetes allows you to find scrape targets from Kubernetes resources.
      // It watches cluster state and ensures targets are continually synced with what is currently running in your cluster.
      discovery.kubernetes "pod" {
        role = "pod"
        selectors {
          role = "pod"
          field = "spec.nodeName=" + coalesce(sys.env("HOSTNAME"), constants.hostname)
        }
      }

      // discovery.relabel rewrites the label set of the input targets by applying one or more relabeling rules.
      // If no rules are defined, then the input targets are exported as-is.
      discovery.relabel "pod_logs" {
        targets = discovery.kubernetes.pod.targets

        // Label creation - "namespace" field from "__meta_kubernetes_namespace"
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "replace"
          target_label = "namespace"
        }

        // Label creation - "pod" field from "__meta_kubernetes_pod_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          action = "replace"
          target_label = "pod"
        }

        // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          action = "replace"
          target_label = "container"
        }

        // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
          action = "replace"
          target_label = "app"
        }

        // Label creation - "container" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
        // Concatenate values __meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name.log
        rule {
          source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
          action = "replace"
          target_label = "__path__"
          separator = "/"
          replacement = "/var/log/pods/*$1/*.log"
        }

        // Label creation -  "container_runtime" field from "__meta_kubernetes_pod_container_id"
        rule {
          source_labels = ["__meta_kubernetes_pod_container_id"]
          action = "replace"
          target_label = "container_runtime"
          regex = "^(\\S+):\\/\\/.+$"
          replacement = "$1"
        }

        rule {
          source_labels = ["__meta_kubernetes_pod_node_name"]
          action = "replace"
          target_label = "node"
        }
      
        // Drop self logs (to avoid infinite error log loop)
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          regex = "^alloy$"
          action = "drop"
        }
      }
      
      local.file_match "pod_logs" {
        path_targets = discovery.relabel.pod_logs.output
      }
  
      loki.source.file "pod_logs" {
        targets    = local.file_match.pod_logs.targets
        forward_to = [loki.process.pod_logs.receiver]
      }

      // loki.process receives log entries from other Loki components, applies one or more processing stages,
      // and forwards the results to the list of receivers in the component's arguments.
      loki.process "pod_logs" {
        stage.cri {}
        stage.timestamp {
          format = "RFC3339Nano"
          source = "timestamp"
        }
        stage.output {
          source = "message"
        }
      
        stage.limit {
          rate = 100
          burst = 1000
        }
      
        stage.static_labels {
          values = {
            cluster = "moto-a1",
            job = "pod-logs",
          }
        }
  
        forward_to = [loki.write.vl.receiver, otelcol.receiver.loki.gcp_logs.receiver]
      }
      
      loki.write "vl" {
        endpoint {
          // Prevent auto-parse of JSON messages from ns-apps applications for displaying in NeoShowcase dashboard
          // https://docs.victoriametrics.com/victorialogs/data-ingestion/promtail/index.html
          url = "http://vl-victoria-logs-single-server.victoria-logs.svc.cluster.local:9428/insert/loki/api/v1/push?disable_message_parsing=1&_stream_fields=job,cluster,node,namespace,pod,container"
        }
      }
      
      otelcol.receiver.loki "gcp_logs" {
        output {
          logs = [otelcol.processor.transform.gcp_logs.input]
        }
      }
      
      otelcol.processor.transform "gcp_logs" {
        log_statements {
          context = "log"
          conditions = [
            `Substring(body, 0, 1) == "{"`,
          ]
          statements = [
            `set(cache["parsed"], ParseJSON(body))`,
            `set(body, cache["parsed"])`,
          ]
        }
      
        output {
          metrics = [otelcol.processor.memory_limiter.gcp_logs.input]
          logs = [otelcol.processor.memory_limiter.gcp_logs.input]
          traces = [otelcol.processor.memory_limiter.gcp_logs.input]
        }
      }
      
      otelcol.processor.memory_limiter "gcp_logs" {
        check_interval = "1s"
        limit = "500MiB"
      
        output {
          metrics = [otelcol.processor.batch.gcp_logs.input]
          logs = [otelcol.processor.batch.gcp_logs.input]
          traces = [otelcol.processor.batch.gcp_logs.input]
        }
      }
      
      otelcol.processor.batch "gcp_logs" {
        output {
          metrics = [otelcol.exporter.googlecloud.gcp_logs.input]
          logs = [otelcol.exporter.googlecloud.gcp_logs.input]
          traces = [otelcol.exporter.googlecloud.gcp_logs.input]
        }
      }
      
      otelcol.exporter.googlecloud "gcp_logs" {
        log {
          default_log_name = "opentelemetry.io/collector-exported-log"
        }
      }

  storagePath: /run/alloy
  extraArgs:
    - --feature.community-components.enabled=true
  extraEnv:
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: /etc/otelcol-contrib/key.json
  mounts:
    varlog: true
    extra:
      - name: alloy
        mountPath: /run/alloy
      - name: sa
        mountPath: /etc/otelcol-contrib/key.json
        subPath: key.json

crds:
  create: false

image:
  pullPolicy: Always

controller:
  type: daemonset
  tolerations:
    - operator: Exists
  volumes:
    extra:
      - name: alloy
        hostPath:
          path: /run/alloy-ds
      - name: sa
        secret:
          secretName: sa
